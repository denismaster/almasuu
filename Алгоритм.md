## Алгоритм работы транслятора
Алгоритм трансляции состоит из следующих этапов:

1. Открытие и парсинг файла на _токены_ 
2. Анализ _токенов_ и построение _объектной модели программы_
3. Генерация _объектного кода_ на основе объектной модели и запись в файл.

### Открытие и парсинг файла на токены
В самом начале алгоритма, файл с кодом считывается и разбивается на массив строк. 
Пример разбиения:

_Файл code.asm_
```asm
mov ax, 1
mov cx, 0
```
Результат разбиения на строки:
```java
[
   "mov ax,1",
   "mov cx,0"
]
```
Следующим большим шагом идет парсинг каждой строки на _лексемы_ и формирование из лексем _токенов_.

**Лексема** - распознанная последовательность символов в тексте, которая имеет определенное значение.  
**Токен** - объект, который хранит в себе лексему, а также ее тип.
Пример разбиения:

`mov ax,  1`  - исходная строка файла
`["mov", "ax", "1"]` - разбитая на слова-лексемы.
Далее рассматриваем каждое слово и определяем его тип.

`"mov"` - команда, получаем `{Command, "mov"}` - полученный токен команды
`"ax"` - регистр, получаем `{Register, "ax"}` - токен регистра
`"1"` - какое-то значение, получаем `{Number, "1"}` - токен значения.

Аналогично определяются токены- директивы. В ходе анализа на токены комментарии исключаются. Если же тип лексемы не удалось определить, ей ставится значение "Other".

Все полученные токены с одной строки объединяются в набор `TokenLine`. Таким образом, каждой строке исходного файла соответствует набор `TokenLine`

Третий шаг - определение переменных и меток.

На данном этапе мы совершаем еще один проход по нашему файлу, но теперь по каждому набору токенов. 
При этом рассматриваются только те токены, у которых ранее не удалось установить тип(Other).
Правила определения:
-  Если значение лексемы состоит из 1 слова, а заканчивается на `:`,  при этом этого слова нет в списке меток, то мы нашли определение метки, меняем тип токена на Label.
-  Если значение лексемы не содержит двоеточия, при этом у нас  это слово есть уже в списке меток, то мы нашли ссылку на метку, ставим тип токена (LabelLink).
-  Если слова в списке нет, но при этом следующий токен является токеном сегмента( SEGMENT) или же конца сегмента (ENDS), то мы нашли сегмент (SegmentStart, SegmentEnds)
-  Если слова в списке нет, но следующий токен является директивой определения( DW или DB), то мы нашли переменную. (Variable)

При этом все найденные переменные, сегменты и метки запоминаются. После этого вновь проходим по набору токенов и меням тип токена у тех токенов, которые по факту ссылки на метку или на переменную, но при этом сами метки или переменные объявлены позже.

Если же в наборе остались нераспознанные токены - ругаемся на них.

Итоговый сформированный набор токенов, набор меток, сегментов и переменных является объектом `TokenParsingResult`, который далее(если нет ошибок) передается на этап анализа.

### Анализ токенов и построение объектной модели программы
Далее необходимо построить объектную модель программы - специальной структуры, которая будет содержать описание всей программы в виде объектов.
Причем сразу несколько токенов могут замещаться одной объектом-командой.
Например:

`{Command, "mov"}, {Register, "ax"}, {Number, "1"}` превращается в следующий объект:
`new ImRegMovCommand(ax, 1, false)`.

Каждая команда имеет метод generateCode(), который выводит ее машинный код.

В ходе анализа получаем набор объектов-команд. 

### Генерация _объектного кода_ на основе объектной модели и запись в файл.
На основе набора команд вызываем у них метод generateCode(). Далее этот код записываем в выходной файл.
